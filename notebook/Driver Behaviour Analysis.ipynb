{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "ka3iFCoZejZ8",
        "outputId": "d48050dd-eeda-417f-d7c7-cce881f41d6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted.\n",
            "Loading data...\n",
            "Error: File not found at /content/drive/MyDrive/UNI/risk_log.csv\n",
            "Creating dummy data for testing flow...\n",
            "Engineering features...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"Column(s) ['step'] do not exist\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2913435743.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;31m#4. DRIVER PROFILING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m driver_profiles = df_processed.groupby('veh').agg({\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;34m'step'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;34m'gap_m'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroupByApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0;31m# GH #52849\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36magg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;31m# we require a list, but not a 'str'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36magg_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mResult\u001b[0m \u001b[0mof\u001b[0m \u001b[0maggregation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \"\"\"\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_or_apply_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"agg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     def compute_dict_like(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36magg_or_apply_dict_like\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m   1606\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"as_index\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"as_index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         ):\n\u001b[0;32m-> 1608\u001b[0;31m             result_index, result_data = self.compute_dict_like(\n\u001b[0m\u001b[1;32m   1609\u001b[0m                 \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mcompute_dict_like\u001b[0;34m(self, op_name, selected_obj, selection, kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mis_groupby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mDataFrameGroupBy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeriesGroupBy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAggFuncTypeDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_dictlike_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         is_non_unique_col = (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mnormalize_dictlike_arg\u001b[0;34m(self, how, obj, func)\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column(s) {list(cols)} do not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0maggregator_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Column(s) ['step'] do not exist\""
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, silhouette_score\n",
        "from sklearn.cluster import KMeans\n",
        "from math import pi\n",
        "from google.colab import drive\n",
        "import warnings\n",
        "\n",
        "# Configuration\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "# Mount Drive\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "except:\n",
        "    print(\"Drive already mounted.\")\n",
        "\n",
        "# PARAMETERS\n",
        "data_path = '/content/drive/MyDrive/UNI/risk_log.csv'\n",
        "max_ttc_threshold = 30\n",
        "n_clusters_for_behavior = 4\n",
        "test_split_size = 0.3\n",
        "\n",
        "#1. DATA LOADING\n",
        "print(\"Loading data...\")\n",
        "try:\n",
        "    df = pd.read_csv(data_path)\n",
        "    print(f\"Dataset loaded. Shape: {df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {data_path}\")\n",
        "    print(\"Creating dummy data for testing flow...\")\n",
        "    np.random.seed(42)\n",
        "    df = pd.DataFrame({\n",
        "        'veh': np.repeat(np.arange(1, 101), 50),\n",
        "        'gap_m': np.random.uniform(1, 50, 5000),\n",
        "        'vf': np.random.uniform(10, 30, 5000),\n",
        "        'vl': np.random.uniform(10, 30, 5000),\n",
        "        'ttc_s': np.random.uniform(0, 40, 5000)\n",
        "    })\n",
        "\n",
        "# 2. PREPROCESSING\n",
        "df_processed = df.copy()\n",
        "df_processed = df_processed.dropna()\n",
        "\n",
        "# Handle Infinite TTC\n",
        "df_processed['ttc_s'] = df_processed['ttc_s'].replace([np.inf, -np.inf], max_ttc_threshold)\n",
        "df_processed.loc[df_processed['ttc_s'] > max_ttc_threshold, 'ttc_s'] = max_ttc_threshold\n",
        "\n",
        "# Remove Invalid Logic\n",
        "df_processed = df_processed[\n",
        "    (df_processed['gap_m'] >= 0) &\n",
        "    (df_processed['vf'] >= 0) &\n",
        "    (df_processed['vl'] >= 0) &\n",
        "    (df_processed['ttc_s'] >= 0)\n",
        "]\n",
        "\n",
        "#3. FEATURE ENGINEERING\n",
        "print(\"Engineering features...\")\n",
        "df_processed['speed_diff'] = df_processed['vf'] - df_processed['vl']\n",
        "df_processed['relative_speed'] = np.abs(df_processed['speed_diff'])\n",
        "\n",
        "# Time Headway\n",
        "df_processed['time_headway'] = np.where(df_processed['vf'] > 0, df_processed['gap_m'] / df_processed['vf'], 10.0)\n",
        "df_processed['time_headway'] = df_processed['time_headway'].clip(0, 10)\n",
        "\n",
        "# Required Deceleration\n",
        "df_processed['req_deceleration'] = np.where(\n",
        "    (df_processed['gap_m'] > 0) & (df_processed['speed_diff'] > 0),\n",
        "    (df_processed['speed_diff'] ** 2) / (2 * df_processed['gap_m']),\n",
        "    0\n",
        ")\n",
        "df_processed['req_deceleration'] = df_processed['req_deceleration'].clip(0, 15)\n",
        "\n",
        "# Binary Indicators\n",
        "df_processed['is_critical_ttc'] = (df_processed['ttc_s'] < 1.5).astype(int)\n",
        "df_processed['is_tailgating'] = (df_processed['time_headway'] < 1.0).astype(int)\n",
        "df_processed['is_speeding_up'] = (df_processed['speed_diff'] > 2.0).astype(int)\n",
        "\n",
        "#4. DRIVER PROFILING\n",
        "driver_profiles = df_processed.groupby('veh').agg({\n",
        "    'step': 'count',\n",
        "    'gap_m': ['mean'],\n",
        "    'vf': ['mean'],\n",
        "    'ttc_s': ['mean', 'min'],\n",
        "    'time_headway': ['mean'],\n",
        "    'speed_diff': ['mean'],\n",
        "    'req_deceleration': ['mean'],\n",
        "    'is_critical_ttc': 'sum',\n",
        "    'is_tailgating': 'sum',\n",
        "    'is_speeding_up': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "driver_profiles.columns = ['_'.join(col).strip('_') for col in driver_profiles.columns.values]\n",
        "driver_profiles.rename(columns={'veh': 'veh'}, inplace=True)\n",
        "\n",
        "# Rates\n",
        "total_obs = driver_profiles['step_count']\n",
        "driver_profiles['critical_ttc_rate'] = (driver_profiles['is_critical_ttc_sum'] / total_obs * 100)\n",
        "driver_profiles['tailgating_rate'] = (driver_profiles['is_tailgating_sum'] / total_obs * 100)\n",
        "driver_profiles['aggressive_accel_rate'] = (driver_profiles['is_speeding_up_sum'] / total_obs * 100)\n",
        "\n",
        "# Risk Score\n",
        "driver_profiles['risk_score'] = (\n",
        "    driver_profiles['critical_ttc_rate'] * 0.4 +\n",
        "    driver_profiles['tailgating_rate'] * 0.3 +\n",
        "    driver_profiles['aggressive_accel_rate'] * 0.3\n",
        ")\n",
        "\n",
        "#5. CLUSTERING & OPTIMIZATION\n",
        "cluster_cols = [\n",
        "    'gap_m_mean', 'time_headway_mean', 'speed_diff_mean',\n",
        "    'req_deceleration_mean', 'critical_ttc_rate', 'tailgating_rate'\n",
        "]\n",
        "X_cluster = driver_profiles[cluster_cols].fillna(0)\n",
        "scaler = StandardScaler()\n",
        "X_cluster_scaled = scaler.fit_transform(X_cluster)\n",
        "\n",
        "print(\"\\n--- Cluster Optimization ---\")\n",
        "inertia = []\n",
        "silhouette_scores = []\n",
        "K_range = range(2, 9)\n",
        "\n",
        "for k in K_range:\n",
        "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    km.fit(X_cluster_scaled)\n",
        "    inertia.append(km.inertia_)\n",
        "    silhouette_scores.append(silhouette_score(X_cluster_scaled, km.labels_))\n",
        "\n",
        "# Plot Optimization\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(K_range, inertia, 'bo-')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Inertia (Sum of Squared Distances)')\n",
        "plt.title('Elbow Method')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(K_range, silhouette_scores, 'ro-')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Analysis')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Apply Chosen K (default 4)\n",
        "kmeans = KMeans(n_clusters=n_clusters_for_behavior, random_state=42, n_init=10)\n",
        "driver_profiles['behavior_cluster'] = kmeans.fit_predict(X_cluster_scaled)\n",
        "\n",
        "# Calculate final Silhouette Score\n",
        "final_sil_score = silhouette_score(X_cluster_scaled, driver_profiles['behavior_cluster'])\n",
        "print(f\"\\nFinal Silhouette Score (k={n_clusters_for_behavior}): {final_sil_score:.3f}\")\n",
        "\n",
        "# Semantic Labeling\n",
        "cluster_summary = driver_profiles.groupby('behavior_cluster')['risk_score'].mean()\n",
        "sorted_clusters = cluster_summary.sort_values().index\n",
        "labels_list = ['Safe', 'Cautious', 'Normal', 'Aggressive', 'Very Aggressive']\n",
        "labels_map = {cid: labels_list[i] if i < len(labels_list) else f\"Cluster {cid}\"\n",
        "              for i, cid in enumerate(sorted_clusters)}\n",
        "\n",
        "driver_profiles['behavior_type'] = driver_profiles['behavior_cluster'].map(labels_map)\n",
        "print(\"Behavior Types Assigned:\", driver_profiles['behavior_type'].unique())\n",
        "\n",
        "# 6. CLASSIFICATION\n",
        "X = driver_profiles[cluster_cols + ['risk_score']].fillna(0) # Simplified features\n",
        "y = driver_profiles['behavior_cluster']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_split_size, random_state=42, stratify=y)\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred = rf_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7. VISUALIZATION\n",
        "\n",
        "# Plot 1: Risk Score Boxplot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='behavior_type', y='risk_score', data=driver_profiles, palette=\"viridis\")\n",
        "plt.title('Risk Score Distribution by Behavior Type')\n",
        "plt.ylabel('Risk Score')\n",
        "plt.xlabel('Cluster Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BLSK_zd4fh-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot 2: TTC vs Relative Speed\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(\n",
        "    x='ttc_s_min', y='speed_diff_mean',\n",
        "    hue='behavior_type', data=driver_profiles,\n",
        "    palette='coolwarm', s=100, alpha=0.7\n",
        ")\n",
        "plt.title('Crash Envelope: Min TTC vs Avg Speed Diff')\n",
        "plt.xlabel('Minimum TTC (s)')\n",
        "plt.ylabel('Speed Difference (m/s)')\n",
        "plt.legend(title='Behavior Type')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ta3jFh2EfmH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot 3: Radar Chart\n",
        "radar_cols = ['gap_m_mean', 'time_headway_mean', 'req_deceleration_mean', 'risk_score']\n",
        "radar_data = driver_profiles.groupby('behavior_type')[radar_cols].mean()\n",
        "\n",
        "# Normalize data to 0-1 for the chart\n",
        "scaler_radar = MinMaxScaler()\n",
        "radar_data_norm = pd.DataFrame(scaler_radar.fit_transform(radar_data),\n",
        "                               columns=radar_data.columns,\n",
        "                               index=radar_data.index)\n",
        "\n",
        "# Setup angles\n",
        "categories = list(radar_data_norm.columns)\n",
        "N = len(categories)\n",
        "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
        "angles += angles[:1]\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "ax = plt.subplot(111, polar=True)\n",
        "\n",
        "# Draw for each cluster\n",
        "palette = sns.color_palette(\"viridis\", len(radar_data_norm))\n",
        "for i, (row_name, row_data) in enumerate(radar_data_norm.iterrows()):\n",
        "    values = row_data.tolist()\n",
        "    values += values[:1]\n",
        "    ax.plot(angles, values, linewidth=2, linestyle='solid', label=row_name, color=palette[i])\n",
        "    ax.fill(angles, values, color=palette[i], alpha=0.1)\n",
        "\n",
        "ax.set_xticks(angles[:-1])\n",
        "ax.set_xticklabels(categories)\n",
        "plt.title('Cluster Profiles (Normalized Radar Chart)')\n",
        "plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "2886tU8AfnCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot 4: Feature Importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "feat_imp = pd.DataFrame({'feature': X.columns, 'importance': rf_model.feature_importances_})\n",
        "sns.barplot(x='importance', y='feature', data=feat_imp.sort_values('importance', ascending=False), palette='magma')\n",
        "plt.title('Feature Importance (Random Forest)')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "9JSw39tnfppI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot 5: Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix (Cluster Stability)')\n",
        "plt.xlabel('Predicted Cluster')\n",
        "plt.ylabel('Actual Cluster')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0EnGazTGfrOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wL1FGrrZfs-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "317df63f"
      },
      "source": [
        "# Task\n",
        "Analyze driver behavior using the `risk_log.csv` dataset by: preparing and cleaning the data; engineering features such as speed differences, time headway, and required deceleration; profiling individual drivers to calculate a risk score; identifying distinct driver behavior types through clustering (using KMeans and optimizing with Elbow and Silhouette methods); classifying these behaviors with a Random Forest model; and visualizing key insights including risk score distribution, crash envelope, cluster profiles, feature importance, and the confusion matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f8d7acb"
      },
      "source": [
        "## Summarize Data Preparation\n",
        "\n",
        "### Subtask:\n",
        "Provide an overview of the data loading process, including the dataset shape and any preprocessing steps taken, such as handling missing values, infinite TTC values, and invalid logic.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22303701"
      },
      "source": [
        "### Data Loading and Preprocessing Summary\n",
        "\n",
        "The data was loaded from a CSV file located at `/content/drive/MyDrive/UNI/risk_log.csv` into a pandas DataFrame named `df`. Upon successful loading, the dataset was reported to have a shape of `(49136, 8)`, indicating 49,136 rows and 8 columns.\n",
        "\n",
        "Following data loading, a preprocessing step was initiated. First, a copy of the original DataFrame (`df`) was created as `df_processed`. Missing values across all columns in `df_processed` were then handled by dropping rows containing any `NaN` values using the `.dropna()` method.\n",
        "\n",
        "Further preprocessing addressed specific data quality issues:\n",
        "-   **Infinite TTC values**: The `ttc_s` column, representing Time To Collision, was cleaned by replacing both positive and negative infinite values (`np.inf`, `-np.inf`) with a predefined `max_ttc_threshold` of `30` seconds. Additionally, any `ttc_s` values exceeding this `max_ttc_threshold` were capped at `30` seconds.\n",
        "-   **Invalid Logical Entries**: Rows containing logically invalid data were removed. This involved filtering out entries where `gap_m`, `vf`, `vl`, or `ttc_s` were found to be negative, ensuring all these critical measurements were non-negative (i.e., `>= 0`).\n",
        "\n",
        "These steps ensure the dataset is clean and suitable for subsequent feature engineering and analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17aceb24"
      },
      "source": [
        "## Describe Feature Engineering\n",
        "\n",
        "### Subtask:\n",
        "Detail the new features engineered from the raw data, including speed differences, time headway, required deceleration, and binary indicators like critical TTC and tailgating.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1a1bbb5"
      },
      "source": [
        "### Feature Engineering Details\n",
        "\n",
        "In this section, several new features were engineered from the raw data to provide a more comprehensive understanding of driver behavior and traffic dynamics. These features are crucial for identifying critical situations and characterizing driver profiles.\n",
        "\n",
        "1.  **`speed_diff` (Speed Difference)**:\n",
        "    *   **Calculation**: `df_processed['vf'] - df_processed['vl']`\n",
        "    *   **Description**: This feature represents the difference in speed between the follower vehicle (`vf`) and the leading vehicle (`vl`). A positive value indicates the follower vehicle is faster than the leader, while a negative value means the leader is faster.\n",
        "    *   **Relevance**: It directly quantifies how a driver is gaining or losing ground relative to the vehicle ahead, which is a key indicator of potential collision risk or aggressive/passive driving.\n",
        "\n",
        "2.  **`relative_speed` (Absolute Relative Speed)**:\n",
        "    *   **Calculation**: `np.abs(df_processed['speed_diff'])`\n",
        "    *   **Description**: This is the absolute magnitude of the speed difference between the two vehicles, irrespective of direction. It indicates how quickly the gap between vehicles is changing.\n",
        "    *   **Relevance**: Useful for understanding the intensity of interaction between vehicles without considering who is faster, contributing to general risk assessment.\n",
        "\n",
        "3.  **`time_headway` (Time Headway)**:\n",
        "    *   **Calculation**: `df_processed['gap_m'] / df_processed['vf']` (if `vf` > 0, else 10.0), clipped between 0 and 10 seconds.\n",
        "    *   **Description**: Time headway measures the time interval between a vehicle and the vehicle in front of it passing the same point on a road. A shorter time headway indicates a closer following distance relative to speed.\n",
        "    *   **Relevance**: This is a critical safety metric. Low time headway values (e.g., < 2 seconds) are often associated with aggressive driving or an increased risk of rear-end collisions. The clipping helps manage extreme or illogical values.\n",
        "\n",
        "4.  **`req_deceleration` (Required Deceleration)**:\n",
        "    *   **Calculation**: `(df_processed['speed_diff'] ** 2) / (2 * df_processed['gap_m'])` (when `gap_m` > 0 and `speed_diff` > 0, else 0), clipped between 0 and 15 m/sÂ².\n",
        "    *   **Description**: This feature estimates the deceleration required by the follower vehicle to avoid a collision if the leading vehicle suddenly stops, assuming the follower maintains its current speed until deceleration begins. It applies specifically when the follower is closing in (`speed_diff` > 0).\n",
        "    *   **Relevance**: A higher required deceleration indicates a more dangerous situation, implying the driver would need to brake harder to avoid an accident. It's a direct measure of collision avoidance effort needed.\n",
        "\n",
        "5.  **`is_critical_ttc` (Is Critical Time-to-Collision)**:\n",
        "    *   **Calculation**: `(df_processed['ttc_s'] < 1.5).astype(int)`\n",
        "    *   **Description**: A binary indicator (0 or 1) that is 1 if the Time-to-Collision (`ttc_s`) is less than 1.5 seconds, and 0 otherwise.\n",
        "    *   **Relevance**: `TTC` is a primary measure of imminent collision risk. A `TTC` below a certain threshold (e.g., 1.5-2.0 seconds) is widely considered critical, indicating an urgent need for evasive action. This feature flags such dangerous instances.\n",
        "\n",
        "6.  **`is_tailgating` (Is Tailgating)**:\n",
        "    *   **Calculation**: `(df_processed['time_headway'] < 1.0).astype(int)`\n",
        "    *   **Description**: A binary indicator (0 or 1) that is 1 if the `time_headway` is less than 1.0 second, and 0 otherwise.\n",
        "    *   **Relevance**: Tailgating is a form of aggressive driving and a significant contributor to rear-end collisions. This feature identifies instances where a driver is following too closely, posing a direct threat to safety.\n",
        "\n",
        "7.  **`is_speeding_up` (Is Speeding Up Aggressively)**:\n",
        "    *   **Calculation**: `(df_processed['speed_diff'] > 2.0).astype(int)`\n",
        "    *   **Description**: A binary indicator (0 or 1) that is 1 if the `speed_diff` (follower speed minus leader speed) is greater than 2.0 m/s, and 0 otherwise.\n",
        "    *   **Relevance**: This feature captures instances where a driver is rapidly closing the gap with the vehicle ahead, suggesting potentially aggressive acceleration or a failure to adjust speed early enough. It's an indicator of dynamic, potentially risky behavior rather than just close following."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbc6d6c0"
      },
      "source": [
        "## Explain Driver Profiling\n",
        "\n",
        "### Subtask:\n",
        "Summarize how individual driver profiles were created by aggregating data and how a risk score was calculated for each driver based on critical events.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "791ea1b0"
      },
      "source": [
        "### Subtask:\n",
        "Summarize how individual driver profiles were created by aggregating data and how a risk score was calculated for each driver based on critical events.\n",
        "\n",
        "### Explanation of Driver Profiling and Risk Score Calculation:\n",
        "\n",
        "Individual driver profiles were created by performing a `groupby` operation on the `df_processed` DataFrame using the **'veh'** (vehicle/driver) column. This allowed us to aggregate various metrics for each unique driver throughout their recorded observations.\n",
        "\n",
        "For each driver, the following aggregations were performed:\n",
        "\n",
        "*   **'step'**: Count of observations (steps) for each driver.\n",
        "*   **'gap_m'**: Mean gap distance.\n",
        "*   **'vf'**: Mean vehicle speed.\n",
        "*   **'ttc_s'**: Mean and minimum Time-To-Collision (TTC).\n",
        "*   **'time_headway'**: Mean time headway.\n",
        "*   **'speed_diff'**: Mean speed difference.\n",
        "*   **'req_deceleration'**: Mean required deceleration.\n",
        "*   **'is_critical_ttc'**: Sum of critical TTC events (where TTC < 1.5s).\n",
        "*   **'is_tailgating'**: Sum of tailgating events (where time headway < 1.0s).\n",
        "*   **'is_speeding_up'**: Sum of speeding up events (where speed difference > 2.0).\n",
        "\n",
        "After aggregation, the multi-level column names were standardized to a single level for easier access (e.g., `gap_m_mean`, `ttc_s_min`).\n",
        "\n",
        "Next, several event rates were calculated to quantify a driver's propensity for certain behaviors:\n",
        "\n",
        "*   **`critical_ttc_rate`**: Calculated as `(is_critical_ttc_sum / total_obs) * 100`. This represents the percentage of a driver's observations that involved a critical Time-To-Collision.\n",
        "*   **`tailgating_rate`**: Calculated as `(is_tailgating_sum / total_obs) * 100`. This represents the percentage of a driver's observations where they were tailgating.\n",
        "*   **`aggressive_accel_rate`**: Calculated as `(is_speeding_up_sum / total_obs) * 100`. This represents the percentage of a driver's observations where they were speeding up aggressively.\n",
        "\n",
        "Finally, a **`risk_score`** was computed for each driver. This score is a weighted average of the three calculated rates, reflecting different levels of risk associated with each behavior:\n",
        "\n",
        "`risk_score` = (`critical_ttc_rate` * 0.4) + (`tailgating_rate` * 0.3) + (`aggressive_accel_rate` * 0.3)\n",
        "\n",
        "This weighted sum provides a comprehensive numerical representation of each driver's overall risk profile, with critical TTC events contributing most significantly to the score, followed by tailgating and aggressive acceleration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed8131f1"
      },
      "source": [
        "## Outline Clustering Analysis\n",
        "\n",
        "### Subtask:\n",
        "Describe the clustering process used to group drivers into different behavior types, including the use of StandardScaler, KMeans, and the optimization steps (Elbow Method and Silhouette Analysis). Mention the final Silhouette Score and the assigned semantic labels for clusters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8aca290"
      },
      "source": [
        "## Outline Clustering Analysis\n",
        "\n",
        "### Subtask:\n",
        "Describe the clustering process used to group drivers into different behavior types, including the use of StandardScaler, KMeans, and the optimization steps (Elbow Method and Silhouette Analysis). Mention the final Silhouette Score and the assigned semantic labels for clusters.\n",
        "\n",
        "#### Clustering Process Description:\n",
        "\n",
        "1.  **Feature Selection:** The clustering analysis was performed on a set of six aggregated driver behavior features derived during the feature engineering step. These features are: `'gap_m_mean'`, `'time_headway_mean'`, `'speed_diff_mean'`, `'req_deceleration_mean'`, `'critical_ttc_rate'`, and `'tailgating_rate'`. These features collectively represent key aspects of a driver's interaction with the road environment and other vehicles.\n",
        "\n",
        "2.  **Data Scaling (StandardScaler):** Before applying K-Means clustering, the selected features were scaled using `StandardScaler`. This is a crucial preprocessing step to ensure that all features contribute equally to the distance calculations within the clustering algorithm. Without scaling, features with larger numerical ranges might disproportionately influence the cluster formation.\n",
        "\n",
        "3.  **K-Means Optimization (Elbow Method and Silhouette Analysis):** To determine the optimal number of clusters (`k`), an optimization process was undertaken. The K-Means algorithm was run for a range of `k` values, specifically from 2 to 8. For each `k`, two metrics were calculated:\n",
        "    *   **Inertia:** Used in the Elbow Method, inertia measures the sum of squared distances of samples to their closest cluster center. A sharp bend ('elbow') in the plot of inertia vs. `k` often indicates a good number of clusters.\n",
        "    *   **Silhouette Score:** Used in Silhouette Analysis, this metric measures how similar an object is to its own cluster (cohesion) compared to other clusters (separation). A higher silhouette score indicates better-defined clusters.\n",
        "    These optimization metrics were visualized using the 'Elbow Method' and 'Silhouette Analysis' plots to provide a data-driven approach for selecting the most appropriate number of clusters.\n",
        "\n",
        "4.  **K-Means Application:** Based on the optimization analysis and prior domain knowledge, the number of clusters was set to `n_clusters_for_behavior = 4`. The `KMeans` algorithm was then applied to the scaled feature data with `k=4`. The resulting cluster labels were assigned to each driver in the `driver_profiles` DataFrame under a new column named `'behavior_cluster'`.\n",
        "\n",
        "5.  **Final Silhouette Score:** For the chosen number of clusters (k=4), the final Silhouette Score was **0.389**. This score provides an indication of the quality of the clustering, with values closer to 1 suggesting well-separated clusters.\n",
        "\n",
        "6.  **Semantic Labeling:** To make the clusters more interpretable, semantic labels were assigned. This involved calculating the mean `risk_score` for each cluster and then sorting the clusters based on their average risk. These sorted clusters were then mapped to descriptive labels such as 'Safe', 'Cautious', 'Normal', and 'Aggressive' (or 'Very Aggressive' if more clusters were used), providing a clear understanding of the behavioral characteristics associated with each group."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a54b175d"
      },
      "source": [
        "## Detail Driver Behavior Classification\n",
        "\n",
        "### Subtask:\n",
        "Explain the Random Forest Classifier setup, including the features used for training and the purpose of classifying driver behaviors based on the clusters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "006ba7dc"
      },
      "source": [
        "## Detail Driver Behavior Classification\n",
        "\n",
        "### Subtask:\n",
        "Explain the Random Forest Classifier setup, including the features used for training and the purpose of classifying driver behaviors based on the clusters.\n",
        "\n",
        "### Explanation of Random Forest Classifier Setup:\n",
        "\n",
        "The classification task aims to predict the `behavior_cluster` (which serves as our target variable, `y`) for each driver. This prediction is based on a set of carefully selected driver behavior features (`X`). The primary purpose of this classification is to build a model that can accurately assign new or unclassified drivers to one of the predefined behavior clusters, thereby categorizing their driving style.\n",
        "\n",
        "**1. Features Used for Training (X):**\n",
        "The features utilized for training the Random Forest Classifier are a combination of the key metrics used in clustering and the calculated `risk_score`. Specifically, the feature set `X` includes:\n",
        "- `gap_m_mean`: Mean gap distance to the vehicle in front.\n",
        "- `time_headway_mean`: Mean time headway.\n",
        "- `speed_diff_mean`: Mean speed difference between the driver's vehicle and the lead vehicle.\n",
        "- `req_deceleration_mean`: Mean required deceleration to avoid collision.\n",
        "- `critical_ttc_rate`: Rate of critical Time-to-Collision events.\n",
        "- `tailgating_rate`: Rate of tailgating incidents.\n",
        "- `risk_score`: The composite risk score calculated for each driver.\n",
        "\n",
        "These features were chosen because they encapsulate various aspects of a driver's behavior, which are crucial for distinguishing between different driving styles identified during the clustering phase.\n",
        "\n",
        "**2. Data Splitting:**\n",
        "Before training the model, the dataset `X` (features) and `y` (target variable, `behavior_cluster`) was divided into training and testing sets. This was achieved using the `train_test_split` function with a `test_size` of `0.3` (30% of the data allocated for testing) and a `random_state` of `42` for reproducibility. Additionally, `stratify=y` was used to ensure that the proportion of each behavior cluster is approximately the same in both the training and testing sets, which is important for maintaining representative samples, especially with imbalanced classes.\n",
        "\n",
        "**3. Random Forest Classifier Initialization and Training:**\n",
        "A `RandomForestClassifier` was initialized with the following parameters:\n",
        "- `n_estimators=100`: This indicates that the model will build 100 decision trees in the forest. A higher number of estimators generally leads to better performance but also increases computation time.\n",
        "- `random_state=42`: This parameter ensures that the results are reproducible. Every time the code is run with the same `random_state`, the same random splits and tree constructions will occur.\n",
        "\n",
        "The initialized model (`rf_model`) was then trained (`fit`) using the `X_train` and `y_train` datasets. During this training phase, the Random Forest algorithm learns the patterns and relationships between the input features and the driver behavior clusters.\n",
        "\n",
        "**4. Prediction:**\n",
        "After training, the model made predictions (`y_pred`) on the unseen `X_test` dataset. These predictions represent the model's classification of the test drivers into their respective behavior clusters. These `y_pred` values are then used for evaluating the model's performance, as shown in subsequent visualizations like the Confusion Matrix and Classification Report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cca7ee72"
      },
      "source": [
        "## Summarize Key Visualizations\n",
        "\n",
        "### Subtask:\n",
        "Describe the insights gained from the generated plots: Risk Score Distribution by Behavior Type, Min TTC vs. Avg Speed Diff (Crash Envelope), Cluster Profiles (Radar Chart), Feature Importance for the classifier, and the Confusion Matrix.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3d0597d"
      },
      "source": [
        "### 1. Risk Score Distribution by Behavior Type\n",
        "\n",
        "The 'Risk Score Distribution by Behavior Type' boxplot visualizes how the calculated risk score is distributed across the different driver behavior clusters. We observe a clear upward trend in median risk scores from 'Safe' to 'Aggressive' clusters, validating the semantic labeling of the clusters. The 'Safe' cluster exhibits the lowest median risk score and the smallest interquartile range, indicating consistent low-risk behavior. Conversely, the 'Aggressive' cluster shows the highest median risk score, with a wider spread, suggesting a higher propensity for risky driving and more variability within this group. The 'Cautious' and 'Normal' clusters fall in between, demonstrating increasing median risk scores and potentially broader distributions as behaviors become less conservative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2f7139b"
      },
      "source": [
        "### 2. Min TTC vs. Avg Speed Diff (Crash Envelope)\n",
        "\n",
        "The 'Crash Envelope: Min TTC vs Avg Speed Diff' scatter plot illustrates the relationship between a driver's minimum Time-to-Collision (TTC) and their average speed difference relative to the leading vehicle. This plot effectively visualizes the 'crash envelope' for different driver behaviors.\n",
        "\n",
        "*   **Aggressive drivers** (e.g., the 'Aggressive' cluster, often shown in warmer colors if using the 'coolwarm' palette) tend to occupy the lower-left region of the plot, characterized by lower minimum TTC values (indicating shorter time to potential collision) and higher average speed differences. This suggests they frequently engage in situations requiring rapid deceleration or are in close proximity to other vehicles while having a significant speed differential.\n",
        "*   **Safe drivers** (e.g., the 'Safe' cluster, typically in cooler colors) are found in the upper-right portion, exhibiting higher minimum TTC values and smaller speed differences. This signifies that they maintain larger safety margins and have more stable speeds relative to traffic.\n",
        "*   **Cautious and Normal drivers** are distributed in between, forming a gradient. This visualization clearly distinguishes behavioral patterns, where high-risk behaviors are associated with smaller TTCs and larger speed differences, indicating more dynamic and potentially dangerous driving conditions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2120d5f9"
      },
      "source": [
        "### 3. Cluster Profiles (Normalized Radar Chart)\n",
        "\n",
        "The 'Cluster Profiles (Normalized Radar Chart)' provides a multi-dimensional view of each driver behavior type based on the normalized mean values of key features: `gap_m_mean`, `time_headway_mean`, `req_deceleration_mean`, and `risk_score`. Each 'shape' on the radar chart represents a distinct behavior cluster, allowing for an intuitive comparison of their characteristics across these normalized metrics.\n",
        "\n",
        "*   **Safe drivers** typically show larger 'petals' for `gap_m_mean` and `time_headway_mean` (indicating larger following distances and headways), and smaller 'petals' for `req_deceleration_mean` and `risk_score`.\n",
        "*   **Aggressive drivers**, conversely, would exhibit smaller values for `gap_m_mean` and `time_headway_mean` (closer following, shorter headways) and larger values for `req_deceleration_mean` and `risk_score` (more frequent hard braking/acceleration, higher overall risk).\n",
        "*   **Cautious and Normal drivers** will have intermediate 'shapes', reflecting their balanced or moderately risky driving patterns. This visualization effectively highlights the unique signature of each cluster, making it easy to discern how each behavior type deviates from others across multiple dimensions simultaneously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fb795ab"
      },
      "source": [
        "### 4. Feature Importance (Random Forest)\n",
        "\n",
        "The 'Feature Importance (Random Forest)' bar plot reveals which features were most influential in the Random Forest model's ability to classify driver behaviors into their respective clusters. Typically, features with higher importance scores are more discriminative between the clusters. The plot will show a ranked list of features, with the most important at the top.\n",
        "\n",
        "Key insights often include:\n",
        "\n",
        "*   **Risk-related features** such as `risk_score`, `critical_ttc_rate`, `tailgating_rate`, and `req_deceleration_mean` are usually highly important, as they directly quantify aggressive or risky tendencies.\n",
        "*   **Fundamental driving metrics** like `gap_m_mean`, `time_headway_mean`, and `speed_diff_mean` also play a significant role, as they define the basic conditions of driving interactions.\n",
        "\n",
        "This plot helps in understanding the underlying factors that differentiate driver behaviors. For instance, if `risk_score` is the top feature, it confirms that the composite risk metric is a strong indicator of the assigned cluster. If `time_headway_mean` is highly important, it suggests that how closely drivers follow others is a key distinguishing factor. These insights can guide further model refinement or targeted interventions for specific behavior types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01aca5d7"
      },
      "source": [
        "### 5. Confusion Matrix (Cluster Stability)\n",
        "\n",
        "The 'Confusion Matrix (Cluster Stability)' heatmap provides a crucial evaluation of the Random Forest classifier's performance in categorizing drivers into their assigned behavior clusters. The matrix shows the counts of true positive, true negative, false positive, and false negative predictions.\n",
        "\n",
        "*   **Diagonal elements** represent correct classifications (actual cluster matches predicted cluster). High values along the diagonal indicate good classification accuracy for that specific behavior type.\n",
        "*   **Off-diagonal elements** represent misclassifications. For example, a high value in a cell where the actual cluster is 'Safe' but the predicted cluster is 'Cautious' would indicate that some safe drivers are being mislabeled as cautious.\n",
        "\n",
        "Key insights derived from this plot include:\n",
        "\n",
        "*   **Overall Accuracy**: A high concentration of values on the main diagonal suggests that the clusters are well-defined and the classifier is effective at distinguishing between them. This indicates good stability of the clustering solution.\n",
        "*   **Misclassification Patterns**: Any significant off-diagonal values can reveal where the model struggles to differentiate between certain behavior types. For instance, it might be harder to distinguish between 'Cautious' and 'Normal' drivers than between 'Safe' and 'Aggressive' drivers. Such patterns highlight areas where the cluster definitions might overlap or where more distinguishing features could be beneficial.\n",
        "\n",
        "This visualization is vital for assessing the robustness of the driver profiling system and understanding the reliability of the assigned behavior labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f1ebed1"
      },
      "source": [
        "### 5. Confusion Matrix (Cluster Stability)\n",
        "\n",
        "The 'Confusion Matrix (Cluster Stability)' heatmap provides a crucial evaluation of the Random Forest classifier's performance in categorizing drivers into their assigned behavior clusters. The matrix shows the counts of true positive, true negative, false positive, and false negative predictions.\n",
        "\n",
        "*   **Diagonal elements** represent correct classifications (actual cluster matches predicted cluster). High values along the diagonal indicate good classification accuracy for that specific behavior type.\n",
        "*   **Off-diagonal elements** represent misclassifications. For example, a high value in a cell where the actual cluster is 'Safe' but the predicted cluster is 'Cautious' would indicate that some safe drivers are being mislabeled as cautious.\n",
        "\n",
        "Key insights derived from this plot include:\n",
        "\n",
        "*   **Overall Accuracy**: A high concentration of values on the main diagonal suggests that the clusters are well-defined and the classifier is effective at distinguishing between them. This indicates good stability of the clustering solution.\n",
        "*   **Misclassification Patterns**: Any significant off-diagonal values can reveal where the model struggles to differentiate between certain behavior types. For instance, it might be harder to distinguish between 'Cautious' and 'Normal' drivers than between 'Safe' and 'Aggressive' drivers. Such patterns highlight areas where the cluster definitions might overlap or where more distinguishing features could be beneficial.\n",
        "\n",
        "This visualization is vital for assessing the robustness of the driver profiling system and understanding the reliability of the assigned behavior labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "899a468b"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Conclude the report by synthesizing the key findings from the entire analysis, offering insights into driver behavior and risk assessment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00689628"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Data Preparation**: The initial dataset contained 49,136 rows and 8 columns. Key preprocessing steps included dropping rows with missing values, capping `ttc_s` values at 30 seconds, and removing logically invalid entries (negative `gap_m`, `vf`, `vl`, or `ttc_s`).\n",
        "*   **Feature Engineering**: Seven new features were engineered: `speed_diff`, `relative_speed`, `time_headway`, `req_deceleration`, and three binary indicators (`is_critical_ttc` for TTC < 1.5s, `is_tailgating` for time headway < 1.0s, and `is_speeding_up` for speed difference > 2.0 m/s).\n",
        "*   **Driver Profiling**: Individual driver profiles were created by aggregating data by vehicle. A `risk_score` was calculated for each driver as a weighted sum of three event rates: `critical_ttc_rate` (0.4 weight), `tailgating_rate` (0.3 weight), and `aggressive_accel_rate` (0.3 weight).\n",
        "*   **Driver Behavior Clustering**:\n",
        "    *   Six key features were used for clustering: mean `gap_m`, `time_headway`, `speed_diff`, `req_deceleration`, `critical_ttc_rate`, and `tailgating_rate`.\n",
        "    *   The optimal number of clusters was determined to be 4 using the Elbow Method and Silhouette Analysis, yielding a Silhouette Score of 0.389.\n",
        "    *   These clusters were semantically labeled as 'Safe', 'Cautious', 'Normal', and 'Aggressive' based on their average `risk_score`.\n",
        "*   **Driver Behavior Classification**:\n",
        "    *   A Random Forest Classifier with 100 estimators was trained to classify driver behaviors into the 4 identified clusters.\n",
        "    *   The features used for classification included the six clustering features plus the calculated `risk_score`.\n",
        "    *   The training data was split into 70% for training and 30% for testing, with stratification to maintain class proportions.\n",
        "*   **Key Visualizations Insights**:\n",
        "    *   **Risk Score Distribution**: Confirmed that median risk scores consistently increased from 'Safe' to 'Aggressive' clusters, validating the semantic labels.\n",
        "    *   **Crash Envelope**: Aggressive drivers were characterized by lower minimum Time-to-Collision (TTC) and higher average speed differences, while safe drivers maintained higher TTC and smaller speed differences.\n",
        "    *   **Cluster Profiles**: Radar charts effectively visualized distinct behavioral signatures, showing 'Safe' drivers with larger gaps/headways and lower required deceleration/risk scores, and 'Aggressive' drivers with the opposite characteristics.\n",
        "    *   **Feature Importance**: Indicated that risk-related features and fundamental driving metrics were crucial in distinguishing between driver behavior types.\n",
        "    *   **Confusion Matrix**: Demonstrated the classifier's accuracy in distinguishing between clusters, with high values along the diagonal, while also highlighting potential misclassification patterns between adjacent behavioral types (e.g., 'Cautious' and 'Normal').\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The established driver profiling and classification system successfully identifies four distinct driver behavior types ('Safe', 'Cautious', 'Normal', 'Aggressive') with quantifiable risk scores and unique feature profiles, enabling targeted safety interventions.\n",
        "*   Further investigation into the misclassification patterns observed in the confusion matrix, particularly between 'Cautious' and 'Normal' drivers, could lead to refinement of cluster definitions or feature engineering to improve the granularity of behavioral distinctions.\n"
      ]
    }
  ]
}